{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO7-MqKJApdI",
        "outputId": "fe467eff-477a-446a-94ae-ed6db7b8e13f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4sJc0Q7x7yTS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "Xf_k1rNd_zZk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Reshape, Flatten, Multiply, Dropout, Lambda, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def squeeze_block(x, filter_num, block_number):\n",
        "    squeeze = GlobalAveragePooling2D()(x)\n",
        "    squeeze = Dense(int(filter_num / 2), activation=\"relu\", kernel_initializer=\"he_normal\")(squeeze)\n",
        "\n",
        "    squeeze = Dense(filter_num, activation=\"sigmoid\", kernel_initializer=\"he_normal\",\n",
        "                    name=f\"squeeze_coef_{block_number}\")(squeeze)\n",
        "    squeeze = Reshape((1, 1, filter_num))(squeeze)\n",
        "    c = Multiply()([x, squeeze])\n",
        "    return c\n",
        "\n",
        "def model_gen():\n",
        "    print(\"Building model ...\")\n",
        "    inputs = Input((28, 28, 1))\n",
        "\n",
        "    c = Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
        "               kernel_initializer=\"he_normal\", activation=\"relu\", name=\"conv_before_squeeze\")(inputs)\n",
        "    c = squeeze_block(c, 16, block_number=1)\n",
        "    c = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(c)\n",
        "\n",
        "    c = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
        "               kernel_initializer=\"he_normal\", activation='relu', name=\"conv_after_squeeze\")(c)\n",
        "    c = squeeze_block(c, 32, block_number=2)\n",
        "    c = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(c)\n",
        "\n",
        "    f = Flatten()(c)\n",
        "    d = Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(f)\n",
        "    d = Dropout(rate=0.5)(d)\n",
        "    outputs = Dense(10, activation=\"softmax\", kernel_initializer=\"he_normal\")(d)  # Output layer for 10 classes\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    optim = Adam(learning_rate=0.005)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=['accuracy'])  # Use categorical_crossentropy for classification\n",
        "\n",
        "    return model\n",
        "\n",
        "model = model_gen()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ANpphzA9_5F",
        "outputId": "06f72ef9-f8dc-4f07-bcc7-6acc27d73c20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model ...\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)       [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv_before_squeeze (Conv2  (None, 28, 28, 16)           160       ['input_10[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 16)                   0         ['conv_before_squeeze[0][0]'] \n",
            " 8 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 8)                    136       ['global_average_pooling2d_18[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " squeeze_coef_1 (Dense)      (None, 16)                   144       ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_18 (Reshape)        (None, 1, 1, 16)             0         ['squeeze_coef_1[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_18 (Multiply)      (None, 28, 28, 16)           0         ['conv_before_squeeze[0][0]', \n",
            "                                                                     'reshape_18[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooli  (None, 14, 14, 16)           0         ['multiply_18[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv_after_squeeze (Conv2D  (None, 14, 14, 32)           4640      ['max_pooling2d_18[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 32)                   0         ['conv_after_squeeze[0][0]']  \n",
            " 9 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 16)                   528       ['global_average_pooling2d_19[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " squeeze_coef_2 (Dense)      (None, 32)                   544       ['dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)        (None, 1, 1, 32)             0         ['squeeze_coef_2[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_19 (Multiply)      (None, 14, 14, 32)           0         ['conv_after_squeeze[0][0]',  \n",
            "                                                                     'reshape_19[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooli  (None, 7, 7, 32)             0         ['multiply_19[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)         (None, 1568)                 0         ['max_pooling2d_19[0][0]']    \n",
            "                                                                                                  \n",
            " dense_38 (Dense)            (None, 64)                   100416    ['flatten_9[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 64)                   0         ['dense_38[0][0]']            \n",
            "                                                                                                  \n",
            " dense_39 (Dense)            (None, 10)                   650       ['dropout_9[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 107218 (418.82 KB)\n",
            "Trainable params: 107218 (418.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "X_series = []\n",
        "y_series = []\n",
        "for train_index, val_index in kf.split(x_train):\n",
        "    X_series.append(x_train[train_index])\n",
        "    y_series.append(y_train[train_index])\n",
        "X_test = x_test\n",
        "input_len = (28, 28, 1)\n",
        "batch_size = 50\n",
        "epochs_number = 30"
      ],
      "metadata": {
        "id": "WE90GKqUPY2I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step_decay(epoch):\n",
        "    initial_lrate = 0.005\n",
        "    drop = 0.8\n",
        "    epochs_drop = 5.0\n",
        "    lrate = initial_lrate * np.power(drop, np.floor((1 + epoch) / epochs_drop))\n",
        "    return lrate\n"
      ],
      "metadata": {
        "id": "u5njDHdSlUmY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of X_series:\", len(X_series))\n",
        "print(\"Length of y_series:\", len(y_series))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kg2tsLzoAVf",
        "outputId": "14e1a118-7f6e-4e10-8ffd-2e9171b9b8d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of X_series: 3\n",
            "Length of y_series: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "y_test_predictions = []\n",
        "\n",
        "for i in range(3):\n",
        "    model = model_gen()\n",
        "    X_fit, y_fit = None, None\n",
        "    for j in range(3):\n",
        "        if j != i:\n",
        "            if X_fit is None:\n",
        "                X_fit, y_fit = X_series[j], y_series[j]\n",
        "            else:\n",
        "                X_fit = np.concatenate((X_fit, X_series[j]), axis=0)\n",
        "                y_fit = np.concatenate((y_fit, y_series[j]), axis=0)\n",
        "\n",
        "    X_val, y_val = X_series[i], y_series[i]\n",
        "\n",
        "\n",
        "    model.fit(X_fit, y_fit, batch_size=batch_size, epochs=epochs_number,\n",
        "              validation_data=(X_val, y_val), shuffle=True, callbacks=[lrate])\n",
        "    model_loss = np.zeros((5,), dtype=np.float32)\n",
        "    y_pred_series = []\n",
        "\n",
        "    model_loss[i] = model.evaluate(X_val, y_val)[0]\n",
        "    pred = model.predict(X_val)\n",
        "    y_pred_series.append(pred)\n",
        "\n",
        "    y_test_predictions.append(model.predict(X_test))\n",
        "\n",
        "if y_test_predictions:\n",
        "    y_test_ensemble = np.mean(y_test_predictions, axis=0)\n",
        "\n",
        "model.save_weights(filepath=\"model_param.hdf5\")\n",
        "\n",
        "model_loss_mean = np.mean(model_loss)\n",
        "model_loss_std = np.std(model_loss)\n",
        "print(\"CV Score for the model is {:.3f} +/- {:.3f}\".format(model_loss_mean, model_loss_std))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdPUs5CKEEhL",
        "outputId": "cf6c6eac-2ea5-4fb8-e3ea-dfe5aebda41d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model ...\n",
            "Epoch 1/30\n",
            "1600/1600 [==============================] - 23s 12ms/step - loss: 2.4426 - accuracy: 0.2167 - val_loss: 1.6684 - val_accuracy: 0.3641 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 1.8660 - accuracy: 0.2762 - val_loss: 1.2357 - val_accuracy: 0.5814 - lr: 0.0050\n",
            "Epoch 3/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 1.2448 - accuracy: 0.5303 - val_loss: 0.2633 - val_accuracy: 0.9376 - lr: 0.0050\n",
            "Epoch 4/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.7354 - accuracy: 0.7379 - val_loss: 0.1723 - val_accuracy: 0.9588 - lr: 0.0050\n",
            "Epoch 5/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.5610 - accuracy: 0.8161 - val_loss: 0.1429 - val_accuracy: 0.9661 - lr: 0.0040\n",
            "Epoch 6/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.4714 - accuracy: 0.8487 - val_loss: 0.1377 - val_accuracy: 0.9637 - lr: 0.0040\n",
            "Epoch 7/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.4148 - accuracy: 0.8666 - val_loss: 0.1202 - val_accuracy: 0.9711 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.3995 - accuracy: 0.8710 - val_loss: 0.1130 - val_accuracy: 0.9705 - lr: 0.0040\n",
            "Epoch 9/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.3736 - accuracy: 0.8782 - val_loss: 0.1062 - val_accuracy: 0.9699 - lr: 0.0040\n",
            "Epoch 10/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.3326 - accuracy: 0.8911 - val_loss: 0.1015 - val_accuracy: 0.9712 - lr: 0.0032\n",
            "Epoch 11/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.3179 - accuracy: 0.8955 - val_loss: 0.1130 - val_accuracy: 0.9707 - lr: 0.0032\n",
            "Epoch 12/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.3056 - accuracy: 0.9008 - val_loss: 0.0814 - val_accuracy: 0.9769 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.2962 - accuracy: 0.9027 - val_loss: 0.0796 - val_accuracy: 0.9776 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2842 - accuracy: 0.9054 - val_loss: 0.0730 - val_accuracy: 0.9802 - lr: 0.0032\n",
            "Epoch 15/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.2588 - accuracy: 0.9125 - val_loss: 0.0652 - val_accuracy: 0.9836 - lr: 0.0026\n",
            "Epoch 16/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2500 - accuracy: 0.9158 - val_loss: 0.0605 - val_accuracy: 0.9821 - lr: 0.0026\n",
            "Epoch 17/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.2398 - accuracy: 0.9187 - val_loss: 0.0655 - val_accuracy: 0.9814 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.2288 - accuracy: 0.9274 - val_loss: 0.0649 - val_accuracy: 0.9841 - lr: 0.0026\n",
            "Epoch 19/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2159 - accuracy: 0.9311 - val_loss: 0.0573 - val_accuracy: 0.9852 - lr: 0.0026\n",
            "Epoch 20/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2019 - accuracy: 0.9373 - val_loss: 0.0527 - val_accuracy: 0.9852 - lr: 0.0020\n",
            "Epoch 21/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.1907 - accuracy: 0.9413 - val_loss: 0.0431 - val_accuracy: 0.9880 - lr: 0.0020\n",
            "Epoch 22/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.1840 - accuracy: 0.9445 - val_loss: 0.0408 - val_accuracy: 0.9896 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.1757 - accuracy: 0.9467 - val_loss: 0.0456 - val_accuracy: 0.9883 - lr: 0.0020\n",
            "Epoch 24/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.1736 - accuracy: 0.9469 - val_loss: 0.0423 - val_accuracy: 0.9885 - lr: 0.0020\n",
            "Epoch 25/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.1632 - accuracy: 0.9489 - val_loss: 0.0354 - val_accuracy: 0.9908 - lr: 0.0016\n",
            "Epoch 26/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.1627 - accuracy: 0.9503 - val_loss: 0.0337 - val_accuracy: 0.9910 - lr: 0.0016\n",
            "Epoch 27/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.1561 - accuracy: 0.9517 - val_loss: 0.0354 - val_accuracy: 0.9909 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.1547 - accuracy: 0.9518 - val_loss: 0.0369 - val_accuracy: 0.9897 - lr: 0.0016\n",
            "Epoch 29/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1512 - accuracy: 0.9532 - val_loss: 0.0321 - val_accuracy: 0.9916 - lr: 0.0016\n",
            "Epoch 30/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1449 - accuracy: 0.9552 - val_loss: 0.0285 - val_accuracy: 0.9918 - lr: 0.0013\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0285 - accuracy: 0.9918\n",
            "1250/1250 [==============================] - 3s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Building model ...\n",
            "Epoch 1/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 1.8939 - accuracy: 0.4318 - val_loss: 0.4906 - val_accuracy: 0.8962 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 1.0030 - accuracy: 0.6462 - val_loss: 0.3537 - val_accuracy: 0.9303 - lr: 0.0050\n",
            "Epoch 3/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.9935 - accuracy: 0.6607 - val_loss: 0.4114 - val_accuracy: 0.9111 - lr: 0.0050\n",
            "Epoch 4/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.8606 - accuracy: 0.7049 - val_loss: 0.2940 - val_accuracy: 0.9388 - lr: 0.0050\n",
            "Epoch 5/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.7094 - accuracy: 0.7636 - val_loss: 0.2184 - val_accuracy: 0.9539 - lr: 0.0040\n",
            "Epoch 6/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.5848 - accuracy: 0.8115 - val_loss: 0.1710 - val_accuracy: 0.9605 - lr: 0.0040\n",
            "Epoch 7/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.5270 - accuracy: 0.8281 - val_loss: 0.1829 - val_accuracy: 0.9572 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.4872 - accuracy: 0.8428 - val_loss: 0.1361 - val_accuracy: 0.9661 - lr: 0.0040\n",
            "Epoch 9/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.4678 - accuracy: 0.8477 - val_loss: 0.1474 - val_accuracy: 0.9637 - lr: 0.0040\n",
            "Epoch 10/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.4470 - accuracy: 0.8531 - val_loss: 0.1242 - val_accuracy: 0.9677 - lr: 0.0032\n",
            "Epoch 11/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.4317 - accuracy: 0.8607 - val_loss: 0.1102 - val_accuracy: 0.9691 - lr: 0.0032\n",
            "Epoch 12/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.4174 - accuracy: 0.8633 - val_loss: 0.1197 - val_accuracy: 0.9692 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.4074 - accuracy: 0.8667 - val_loss: 0.1077 - val_accuracy: 0.9701 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.3827 - accuracy: 0.8739 - val_loss: 0.1029 - val_accuracy: 0.9722 - lr: 0.0032\n",
            "Epoch 15/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.3495 - accuracy: 0.8824 - val_loss: 0.0940 - val_accuracy: 0.9724 - lr: 0.0026\n",
            "Epoch 16/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.3403 - accuracy: 0.8852 - val_loss: 0.0933 - val_accuracy: 0.9752 - lr: 0.0026\n",
            "Epoch 17/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.3339 - accuracy: 0.8867 - val_loss: 0.0942 - val_accuracy: 0.9739 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.3225 - accuracy: 0.8924 - val_loss: 0.0824 - val_accuracy: 0.9762 - lr: 0.0026\n",
            "Epoch 19/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.3096 - accuracy: 0.8938 - val_loss: 0.0798 - val_accuracy: 0.9790 - lr: 0.0026\n",
            "Epoch 20/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 0.2884 - accuracy: 0.9024 - val_loss: 0.0646 - val_accuracy: 0.9821 - lr: 0.0020\n",
            "Epoch 21/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.2790 - accuracy: 0.9046 - val_loss: 0.0754 - val_accuracy: 0.9811 - lr: 0.0020\n",
            "Epoch 22/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.2758 - accuracy: 0.9057 - val_loss: 0.0579 - val_accuracy: 0.9829 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.2686 - accuracy: 0.9082 - val_loss: 0.0567 - val_accuracy: 0.9840 - lr: 0.0020\n",
            "Epoch 24/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.2605 - accuracy: 0.9104 - val_loss: 0.0528 - val_accuracy: 0.9851 - lr: 0.0020\n",
            "Epoch 25/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2398 - accuracy: 0.9186 - val_loss: 0.0497 - val_accuracy: 0.9858 - lr: 0.0016\n",
            "Epoch 26/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2333 - accuracy: 0.9196 - val_loss: 0.0485 - val_accuracy: 0.9865 - lr: 0.0016\n",
            "Epoch 27/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 0.2317 - accuracy: 0.9205 - val_loss: 0.0477 - val_accuracy: 0.9858 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2265 - accuracy: 0.9224 - val_loss: 0.0450 - val_accuracy: 0.9873 - lr: 0.0016\n",
            "Epoch 29/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2202 - accuracy: 0.9247 - val_loss: 0.0411 - val_accuracy: 0.9889 - lr: 0.0016\n",
            "Epoch 30/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 0.2027 - accuracy: 0.9308 - val_loss: 0.0448 - val_accuracy: 0.9869 - lr: 0.0013\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0448 - accuracy: 0.9869\n",
            "1250/1250 [==============================] - 3s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Building model ...\n",
            "Epoch 1/30\n",
            "1600/1600 [==============================] - 15s 8ms/step - loss: 2.6619 - accuracy: 0.1160 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 2.3015 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1049 - lr: 0.0050\n",
            "Epoch 3/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 2.3017 - accuracy: 0.1122 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0050\n",
            "Epoch 4/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3017 - accuracy: 0.1120 - val_loss: 2.3018 - val_accuracy: 0.1115 - lr: 0.0050\n",
            "Epoch 5/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 2.3016 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0040\n",
            "Epoch 6/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3015 - accuracy: 0.1123 - val_loss: 2.3018 - val_accuracy: 0.1115 - lr: 0.0040\n",
            "Epoch 7/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 2.3015 - accuracy: 0.1126 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1049 - lr: 0.0040\n",
            "Epoch 9/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3022 - val_accuracy: 0.1115 - lr: 0.0040\n",
            "Epoch 10/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 2.3015 - accuracy: 0.1125 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0032\n",
            "Epoch 11/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 2.3014 - accuracy: 0.1128 - val_loss: 2.3020 - val_accuracy: 0.1115 - lr: 0.0032\n",
            "Epoch 12/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 2.3015 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 2.3015 - accuracy: 0.1128 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0032\n",
            "Epoch 15/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1126 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0026\n",
            "Epoch 16/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3018 - val_accuracy: 0.1115 - lr: 0.0026\n",
            "Epoch 17/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3018 - val_accuracy: 0.1115 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3014 - accuracy: 0.1128 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0026\n",
            "Epoch 19/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3015 - val_accuracy: 0.1115 - lr: 0.0026\n",
            "Epoch 20/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3014 - val_accuracy: 0.1115 - lr: 0.0020\n",
            "Epoch 21/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0020\n",
            "Epoch 22/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "1600/1600 [==============================] - 11s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3015 - val_accuracy: 0.1115 - lr: 0.0020\n",
            "Epoch 24/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3015 - val_accuracy: 0.1115 - lr: 0.0020\n",
            "Epoch 25/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3016 - val_accuracy: 0.1115 - lr: 0.0016\n",
            "Epoch 26/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.3015 - val_accuracy: 0.1115 - lr: 0.0016\n",
            "Epoch 27/30\n",
            "1600/1600 [==============================] - 12s 7ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3015 - val_accuracy: 0.1115 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.3018 - val_accuracy: 0.1115 - lr: 0.0016\n",
            "Epoch 29/30\n",
            "1600/1600 [==============================] - 12s 8ms/step - loss: 2.3012 - accuracy: 0.1128 - val_loss: 2.3017 - val_accuracy: 0.1115 - lr: 0.0016\n",
            "Epoch 30/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3014 - val_accuracy: 0.1115 - lr: 0.0013\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 2.3014 - accuracy: 0.1115\n",
            "1250/1250 [==============================] - 4s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "CV Score for the model is 0.460 +/- 0.921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando un kfold = 3, con 30 epocas de entrenamiento. Obtenemos una media de la perdida de 0.46 y una desviación estandar en 0.921 Estos son valores muy altos para estas métricas de evaluación. Esto puede deberse a diversos factores como la alta variabilidad de los datos o la arquitectura de nuestro modelo. Buscando mejores resultados, aplicaremos técnicas de regularización así como modificar los hiperparámetro del modelo."
      ],
      "metadata": {
        "id": "C3dTtcaIvpwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l1_l2\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "def squeeze_block(x, filter_num, block_number):\n",
        "\n",
        "    squeeze = GlobalAveragePooling2D()(x)\n",
        "    squeeze = Dense(int(filter_num / 2), activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                    kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(squeeze)\n",
        "\n",
        "\n",
        "    squeeze = Dense(filter_num, activation=\"sigmoid\", kernel_initializer=\"he_normal\",\n",
        "                    name=f\"squeeze_coef_{block_number}\")(squeeze)\n",
        "    squeeze = Reshape((1, 1, filter_num))(squeeze)\n",
        "    c = Multiply()([x, squeeze])\n",
        "    return c\n",
        "\n",
        "def model_gen():\n",
        "    print(\"Building model ...\")\n",
        "    inputs = Input((28, 28, 1))\n",
        "\n",
        "    c = Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
        "               kernel_initializer=\"he_normal\", activation=\"relu\", name=\"conv_before_squeeze\")(inputs)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = squeeze_block(c, 16, block_number=1)\n",
        "    c = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(c)\n",
        "\n",
        "    c = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
        "               kernel_initializer=\"he_normal\", activation='relu', name=\"conv_after_squeeze\")(c)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = squeeze_block(c, 32, block_number=2)\n",
        "    c = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\")(c)\n",
        "\n",
        "    f = Flatten()(c)\n",
        "    d = Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "              kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(f)\n",
        "    d = Dropout(rate=0.5)(d)\n",
        "    outputs = Dense(10, activation=\"softmax\", kernel_initializer=\"he_normal\")(d)  # Output layer for 10 classes\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    optim = Adam(learning_rate=0.005)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=['accuracy'])  # Use categorical_crossentropy for classification\n",
        "\n",
        "    return model\n",
        "\n",
        "model = model_gen()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VSZUYbcyXiS",
        "outputId": "82ccfbfb-ff3a-4577-adee-20e1aa9ba8c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model ...\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)       [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv_before_squeeze (Conv2  (None, 28, 28, 16)           160       ['input_15[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 28, 28, 16)           64        ['conv_before_squeeze[0][0]'] \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 16)                   0         ['batch_normalization[0][0]'] \n",
            " 8 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " dense_56 (Dense)            (None, 8)                    136       ['global_average_pooling2d_28[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " squeeze_coef_1 (Dense)      (None, 16)                   144       ['dense_56[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_28 (Reshape)        (None, 1, 1, 16)             0         ['squeeze_coef_1[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)      (None, 28, 28, 16)           0         ['batch_normalization[0][0]', \n",
            "                                                                     'reshape_28[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_28 (MaxPooli  (None, 14, 14, 16)           0         ['multiply_28[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv_after_squeeze (Conv2D  (None, 14, 14, 32)           4640      ['max_pooling2d_28[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 14, 14, 32)           128       ['conv_after_squeeze[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 32)                   0         ['batch_normalization_1[0][0]'\n",
            " 9 (GlobalAveragePooling2D)                                         ]                             \n",
            "                                                                                                  \n",
            " dense_57 (Dense)            (None, 16)                   528       ['global_average_pooling2d_29[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " squeeze_coef_2 (Dense)      (None, 32)                   544       ['dense_57[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_29 (Reshape)        (None, 1, 1, 32)             0         ['squeeze_coef_2[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)      (None, 14, 14, 32)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    , 'reshape_29[0][0]']         \n",
            "                                                                                                  \n",
            " max_pooling2d_29 (MaxPooli  (None, 7, 7, 32)             0         ['multiply_29[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " flatten_14 (Flatten)        (None, 1568)                 0         ['max_pooling2d_29[0][0]']    \n",
            "                                                                                                  \n",
            " dense_58 (Dense)            (None, 64)                   100416    ['flatten_14[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 64)                   0         ['dense_58[0][0]']            \n",
            "                                                                                                  \n",
            " dense_59 (Dense)            (None, 10)                   650       ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 107410 (419.57 KB)\n",
            "Trainable params: 107314 (419.20 KB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "y_test_predictions = []\n",
        "\n",
        "for i in range(3):\n",
        "    model = model_gen()\n",
        "    X_fit, y_fit = None, None\n",
        "    for j in range(3):\n",
        "        if j != i:\n",
        "            if X_fit is None:\n",
        "                X_fit, y_fit = X_series[j], y_series[j]\n",
        "            else:\n",
        "                X_fit = np.concatenate((X_fit, X_series[j]), axis=0)\n",
        "                y_fit = np.concatenate((y_fit, y_series[j]), axis=0)\n",
        "\n",
        "\n",
        "    X_val, y_val = X_series[i], y_series[i]\n",
        "\n",
        "    model.fit(X_fit, y_fit, batch_size=batch_size, epochs=epochs_number,\n",
        "              validation_data=(X_val, y_val), shuffle=True, callbacks=[lrate, early_stopping])\n",
        "    model_loss = np.zeros((5,), dtype=np.float32)\n",
        "    y_pred_series = []\n",
        "    model_loss[i] = model.evaluate(X_val, y_val)[0]\n",
        "    pred = model.predict(X_val)\n",
        "    y_pred_series.append(pred)\n",
        "\n",
        "    y_test_predictions.append(model.predict(X_test))\n",
        "\n",
        "if y_test_predictions:\n",
        "    y_test_ensemble = np.mean(y_test_predictions, axis=0)\n",
        "\n",
        "model.save_weights(filepath=\"model_param.hdf5\")\n",
        "\n",
        "model_loss_mean = np.mean(model_loss)\n",
        "model_loss_std = np.std(model_loss)\n",
        "print(\"CV Score for the model is {:.3f} +/- {:.3f}\".format(model_loss_mean, model_loss_std))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zErhuVzj2K1L",
        "outputId": "adc93081-67bb-4627-96bb-e309ed249959"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model ...\n",
            "Epoch 1/30\n",
            "1600/1600 [==============================] - 18s 9ms/step - loss: 0.3659 - accuracy: 0.9077 - val_loss: 0.1468 - val_accuracy: 0.9837 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.2077 - accuracy: 0.9654 - val_loss: 0.1379 - val_accuracy: 0.9871 - lr: 0.0050\n",
            "Epoch 3/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1883 - accuracy: 0.9719 - val_loss: 0.1344 - val_accuracy: 0.9861 - lr: 0.0050\n",
            "Epoch 4/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1766 - accuracy: 0.9750 - val_loss: 0.1273 - val_accuracy: 0.9883 - lr: 0.0050\n",
            "Epoch 5/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1531 - accuracy: 0.9785 - val_loss: 0.1036 - val_accuracy: 0.9910 - lr: 0.0040\n",
            "Epoch 6/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1454 - accuracy: 0.9799 - val_loss: 0.1090 - val_accuracy: 0.9902 - lr: 0.0040\n",
            "Epoch 7/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1414 - accuracy: 0.9809 - val_loss: 0.1138 - val_accuracy: 0.9891 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1351 - accuracy: 0.9819 - val_loss: 0.1113 - val_accuracy: 0.9879 - lr: 0.0040\n",
            "Epoch 9/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1335 - accuracy: 0.9821 - val_loss: 0.1074 - val_accuracy: 0.9905 - lr: 0.0040\n",
            "Epoch 10/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1137 - accuracy: 0.9849 - val_loss: 0.0858 - val_accuracy: 0.9927 - lr: 0.0032\n",
            "Epoch 11/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1118 - accuracy: 0.9858 - val_loss: 0.0848 - val_accuracy: 0.9931 - lr: 0.0032\n",
            "Epoch 12/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1113 - accuracy: 0.9855 - val_loss: 0.0834 - val_accuracy: 0.9929 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1078 - accuracy: 0.9858 - val_loss: 0.0784 - val_accuracy: 0.9945 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1076 - accuracy: 0.9863 - val_loss: 0.0779 - val_accuracy: 0.9943 - lr: 0.0032\n",
            "Epoch 15/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0940 - accuracy: 0.9881 - val_loss: 0.0690 - val_accuracy: 0.9949 - lr: 0.0026\n",
            "Epoch 16/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0889 - accuracy: 0.9888 - val_loss: 0.0730 - val_accuracy: 0.9942 - lr: 0.0026\n",
            "Epoch 17/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0899 - accuracy: 0.9888 - val_loss: 0.0679 - val_accuracy: 0.9956 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0882 - accuracy: 0.9891 - val_loss: 0.0692 - val_accuracy: 0.9939 - lr: 0.0026\n",
            "Epoch 19/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0878 - accuracy: 0.9893 - val_loss: 0.0760 - val_accuracy: 0.9922 - lr: 0.0026\n",
            "Epoch 20/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0766 - accuracy: 0.9908 - val_loss: 0.0602 - val_accuracy: 0.9953 - lr: 0.0020\n",
            "Epoch 21/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.0749 - accuracy: 0.9906 - val_loss: 0.0570 - val_accuracy: 0.9962 - lr: 0.0020\n",
            "Epoch 22/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.0738 - accuracy: 0.9910 - val_loss: 0.0538 - val_accuracy: 0.9963 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0742 - accuracy: 0.9903 - val_loss: 0.0578 - val_accuracy: 0.9955 - lr: 0.0020\n",
            "Epoch 24/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0753 - accuracy: 0.9910 - val_loss: 0.0588 - val_accuracy: 0.9959 - lr: 0.0020\n",
            "Epoch 25/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0642 - accuracy: 0.9926 - val_loss: 0.0496 - val_accuracy: 0.9965 - lr: 0.0016\n",
            "Epoch 26/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0636 - accuracy: 0.9923 - val_loss: 0.0459 - val_accuracy: 0.9974 - lr: 0.0016\n",
            "Epoch 27/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0610 - accuracy: 0.9927 - val_loss: 0.0481 - val_accuracy: 0.9969 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0616 - accuracy: 0.9930 - val_loss: 0.0467 - val_accuracy: 0.9971 - lr: 0.0016\n",
            "Epoch 29/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0619 - accuracy: 0.9925 - val_loss: 0.0488 - val_accuracy: 0.9962 - lr: 0.0016\n",
            "Epoch 30/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0565 - accuracy: 0.9938 - val_loss: 0.0387 - val_accuracy: 0.9982 - lr: 0.0013\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0387 - accuracy: 0.9982\n",
            "1250/1250 [==============================] - 3s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Building model ...\n",
            "Epoch 1/30\n",
            "1600/1600 [==============================] - 18s 9ms/step - loss: 0.3964 - accuracy: 0.8962 - val_loss: 0.1540 - val_accuracy: 0.9827 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.2174 - accuracy: 0.9625 - val_loss: 0.1520 - val_accuracy: 0.9831 - lr: 0.0050\n",
            "Epoch 3/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1941 - accuracy: 0.9689 - val_loss: 0.1275 - val_accuracy: 0.9877 - lr: 0.0050\n",
            "Epoch 4/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1827 - accuracy: 0.9720 - val_loss: 0.1244 - val_accuracy: 0.9884 - lr: 0.0050\n",
            "Epoch 5/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1558 - accuracy: 0.9765 - val_loss: 0.1044 - val_accuracy: 0.9908 - lr: 0.0040\n",
            "Epoch 6/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1479 - accuracy: 0.9781 - val_loss: 0.1074 - val_accuracy: 0.9905 - lr: 0.0040\n",
            "Epoch 7/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1419 - accuracy: 0.9796 - val_loss: 0.1000 - val_accuracy: 0.9917 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1365 - accuracy: 0.9798 - val_loss: 0.1037 - val_accuracy: 0.9899 - lr: 0.0040\n",
            "Epoch 9/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1319 - accuracy: 0.9820 - val_loss: 0.1214 - val_accuracy: 0.9851 - lr: 0.0040\n",
            "Epoch 10/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1157 - accuracy: 0.9843 - val_loss: 0.0880 - val_accuracy: 0.9918 - lr: 0.0032\n",
            "Epoch 11/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1120 - accuracy: 0.9844 - val_loss: 0.0804 - val_accuracy: 0.9934 - lr: 0.0032\n",
            "Epoch 12/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1116 - accuracy: 0.9844 - val_loss: 0.0813 - val_accuracy: 0.9926 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1065 - accuracy: 0.9851 - val_loss: 0.0791 - val_accuracy: 0.9926 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1071 - accuracy: 0.9855 - val_loss: 0.0823 - val_accuracy: 0.9929 - lr: 0.0032\n",
            "Epoch 15/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0940 - accuracy: 0.9881 - val_loss: 0.0712 - val_accuracy: 0.9930 - lr: 0.0026\n",
            "Epoch 16/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0914 - accuracy: 0.9874 - val_loss: 0.0735 - val_accuracy: 0.9932 - lr: 0.0026\n",
            "Epoch 17/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0912 - accuracy: 0.9878 - val_loss: 0.0945 - val_accuracy: 0.9880 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.0881 - accuracy: 0.9883 - val_loss: 0.0658 - val_accuracy: 0.9945 - lr: 0.0026\n",
            "Epoch 19/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0872 - accuracy: 0.9883 - val_loss: 0.0633 - val_accuracy: 0.9952 - lr: 0.0026\n",
            "Epoch 20/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0785 - accuracy: 0.9898 - val_loss: 0.0554 - val_accuracy: 0.9963 - lr: 0.0020\n",
            "Epoch 21/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0747 - accuracy: 0.9901 - val_loss: 0.0540 - val_accuracy: 0.9959 - lr: 0.0020\n",
            "Epoch 22/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0744 - accuracy: 0.9901 - val_loss: 0.0557 - val_accuracy: 0.9962 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0730 - accuracy: 0.9899 - val_loss: 0.0538 - val_accuracy: 0.9961 - lr: 0.0020\n",
            "Epoch 24/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0745 - accuracy: 0.9901 - val_loss: 0.0605 - val_accuracy: 0.9940 - lr: 0.0020\n",
            "Epoch 25/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.0660 - accuracy: 0.9914 - val_loss: 0.0494 - val_accuracy: 0.9958 - lr: 0.0016\n",
            "Epoch 26/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.0639 - accuracy: 0.9915 - val_loss: 0.0461 - val_accuracy: 0.9965 - lr: 0.0016\n",
            "Epoch 27/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0611 - accuracy: 0.9922 - val_loss: 0.0486 - val_accuracy: 0.9954 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.0638 - accuracy: 0.9917 - val_loss: 0.0532 - val_accuracy: 0.9951 - lr: 0.0016\n",
            "Epoch 29/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0633 - accuracy: 0.9915 - val_loss: 0.0454 - val_accuracy: 0.9967 - lr: 0.0016\n",
            "Epoch 30/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0557 - accuracy: 0.9930 - val_loss: 0.0389 - val_accuracy: 0.9977 - lr: 0.0013\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0389 - accuracy: 0.9977\n",
            "1250/1250 [==============================] - 4s 3ms/step\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "Building model ...\n",
            "Epoch 1/30\n",
            "1600/1600 [==============================] - 17s 9ms/step - loss: 0.3593 - accuracy: 0.9036 - val_loss: 0.1452 - val_accuracy: 0.9826 - lr: 0.0050\n",
            "Epoch 2/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.2120 - accuracy: 0.9611 - val_loss: 0.1649 - val_accuracy: 0.9787 - lr: 0.0050\n",
            "Epoch 3/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1959 - accuracy: 0.9680 - val_loss: 0.1353 - val_accuracy: 0.9854 - lr: 0.0050\n",
            "Epoch 4/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1787 - accuracy: 0.9721 - val_loss: 0.1204 - val_accuracy: 0.9892 - lr: 0.0050\n",
            "Epoch 5/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1555 - accuracy: 0.9764 - val_loss: 0.1095 - val_accuracy: 0.9897 - lr: 0.0040\n",
            "Epoch 6/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1485 - accuracy: 0.9775 - val_loss: 0.1036 - val_accuracy: 0.9904 - lr: 0.0040\n",
            "Epoch 7/30\n",
            "1600/1600 [==============================] - 14s 8ms/step - loss: 0.1417 - accuracy: 0.9784 - val_loss: 0.1030 - val_accuracy: 0.9906 - lr: 0.0040\n",
            "Epoch 8/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1370 - accuracy: 0.9805 - val_loss: 0.0985 - val_accuracy: 0.9912 - lr: 0.0040\n",
            "Epoch 9/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.1332 - accuracy: 0.9805 - val_loss: 0.1186 - val_accuracy: 0.9866 - lr: 0.0040\n",
            "Epoch 10/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1172 - accuracy: 0.9831 - val_loss: 0.0830 - val_accuracy: 0.9926 - lr: 0.0032\n",
            "Epoch 11/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1123 - accuracy: 0.9832 - val_loss: 0.0869 - val_accuracy: 0.9909 - lr: 0.0032\n",
            "Epoch 12/30\n",
            "1600/1600 [==============================] - 13s 8ms/step - loss: 0.1137 - accuracy: 0.9837 - val_loss: 0.0842 - val_accuracy: 0.9923 - lr: 0.0032\n",
            "Epoch 13/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1091 - accuracy: 0.9845 - val_loss: 0.0825 - val_accuracy: 0.9924 - lr: 0.0032\n",
            "Epoch 14/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.1064 - accuracy: 0.9847 - val_loss: 0.0808 - val_accuracy: 0.9922 - lr: 0.0032\n",
            "Epoch 15/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0949 - accuracy: 0.9866 - val_loss: 0.0654 - val_accuracy: 0.9951 - lr: 0.0026\n",
            "Epoch 16/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0933 - accuracy: 0.9864 - val_loss: 0.0713 - val_accuracy: 0.9937 - lr: 0.0026\n",
            "Epoch 17/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0891 - accuracy: 0.9875 - val_loss: 0.0664 - val_accuracy: 0.9946 - lr: 0.0026\n",
            "Epoch 18/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0907 - accuracy: 0.9870 - val_loss: 0.0624 - val_accuracy: 0.9949 - lr: 0.0026\n",
            "Epoch 19/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0875 - accuracy: 0.9875 - val_loss: 0.0643 - val_accuracy: 0.9953 - lr: 0.0026\n",
            "Epoch 20/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0786 - accuracy: 0.9887 - val_loss: 0.0530 - val_accuracy: 0.9963 - lr: 0.0020\n",
            "Epoch 21/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0754 - accuracy: 0.9896 - val_loss: 0.0533 - val_accuracy: 0.9959 - lr: 0.0020\n",
            "Epoch 22/30\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.0735 - accuracy: 0.9900 - val_loss: 0.0506 - val_accuracy: 0.9966 - lr: 0.0020\n",
            "Epoch 23/30\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.0735 - accuracy: 0.9897 - val_loss: 0.0548 - val_accuracy: 0.9952 - lr: 0.0020\n",
            "Epoch 24/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0757 - accuracy: 0.9893 - val_loss: 0.0576 - val_accuracy: 0.9944 - lr: 0.0020\n",
            "Epoch 25/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0660 - accuracy: 0.9907 - val_loss: 0.0475 - val_accuracy: 0.9964 - lr: 0.0016\n",
            "Epoch 26/30\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.0645 - accuracy: 0.9912 - val_loss: 0.0444 - val_accuracy: 0.9970 - lr: 0.0016\n",
            "Epoch 27/30\n",
            "1600/1600 [==============================] - 16s 10ms/step - loss: 0.0631 - accuracy: 0.9913 - val_loss: 0.0463 - val_accuracy: 0.9966 - lr: 0.0016\n",
            "Epoch 28/30\n",
            "1600/1600 [==============================] - 15s 9ms/step - loss: 0.0621 - accuracy: 0.9909 - val_loss: 0.0416 - val_accuracy: 0.9978 - lr: 0.0016\n",
            "Epoch 29/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0630 - accuracy: 0.9908 - val_loss: 0.0546 - val_accuracy: 0.9944 - lr: 0.0016\n",
            "Epoch 30/30\n",
            "1600/1600 [==============================] - 14s 9ms/step - loss: 0.0564 - accuracy: 0.9924 - val_loss: 0.0386 - val_accuracy: 0.9977 - lr: 0.0013\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0386 - accuracy: 0.9977\n",
            "1250/1250 [==============================] - 4s 3ms/step\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "CV Score for the model is 0.008 +/- 0.015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Igual al modelo anterior, aplicando un kfold = 3, con 30 epocas de entrenamiento. Obtenemos una media de la perdida de 0.008 y una desviación estandar de +- 0.015 Estos son valores muy favorables para el modelo. Sin embargo, tenemos un acurracy que va de 0.9924 a 0.9982. Los cambios realizados desde el modelo anterior consisten en la integración de la regularización a nuestra aqruitectura, en cada una de las capas densas. De manera similar agregamos dos capas de BatchNormalization tras cada una de las capas convolucionales. Por último hemos agregado un Earlystopping para el entrenamiento del modelo con una paciencia de 10, sin emabrgo no lo hemos visto entrar en acción en ninguno de los folds y en al menos 30 epocas."
      ],
      "metadata": {
        "id": "9se0CCSf9SdI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como mejoras a un tercer modelo, aplicariamos un aumento de los datos rotando las imagenes, volteandolas o realizando transformaciones, de esta manera, nuestro modelo podra entrenar sobre imagenes 'nuevas'. Revisar la arquitectura y considerar hacerla menos compleja en busqueda de reducir el sobreajuste que hemos notado. De igual manera reducir los parametros del early stopping para verlo en acción y corroborar si esto nos ayudará en entrenar este modelo de mejor manera."
      ],
      "metadata": {
        "id": "sI2jzJKk_ORG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "index = random.randint(0, len(X_val) - 1)\n",
        "selected_image = X_val[index]\n",
        "selected_image_for_prediction = np.expand_dims(selected_image, axis=0)\n",
        "predicted_label = model.predict(selected_image_for_prediction)\n",
        "predicted_label = np.argmax(predicted_label, axis=1)[0]  plt.figure(figsize=(4, 4))\n",
        "plt.imshow(selected_image, cmap=plt.cm.binary)\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "PHPtHrVpBqCu",
        "outputId": "476c3340-1b95-4c11-dd45-e9cd48a2c4e8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_predictions(images, true_labels, predicted_labels, num_images=10):\n",
        "    num_images = min(num_images, len(images))\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "\n",
        "        plt.xlabel(f\"Predicted: {predicted_labels[i]}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "QGq-cMFa2R6q"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
        "display_image_predictions(X_test, y_test, predicted_labels, num_images=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "XhFZVtwLBI0O",
        "outputId": "69b17b87-a277-46c7-fb26-1b18b3a93679"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}